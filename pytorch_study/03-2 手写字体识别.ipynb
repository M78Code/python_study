{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8301a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# 1 加载必要的库\n",
    "import torch\n",
    "import torch.nn as nn # 神经网络库\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim # 优化器\n",
    "from torchvision import datasets,transforms # torchvison操作数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233bb5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 定义超参数\n",
    "BATCH_SIZE = 256 # 每批处理的数据\n",
    "\n",
    "# 要想像使用服务器的GPU上进行深度学习加速，就需要将模型放到GPU上，在服务器中这个操作是通过\n",
    "# device = torch.device(\"cuda:0\")\n",
    "# model = model.to(device)\n",
    "\n",
    "#DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 是否用GPU还是CPU训练(非Mac系的电脑可以这样写)\n",
    "# 使用Mac系的M芯片进行加速 https://juejin.cn/post/7137891506777489416\n",
    "DEVICE_MACBOOK = torch.device(\"mps\") \n",
    "EPOCHS = 100 # 训练数据集的轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dce201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 构建pipeline, 对图像做处理\n",
    "pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(), # 将图片转换成tensor\n",
    "    transforms.Normalize((0.1307,),(0.3081,)) # 对图片进行正则化,作用，当模型出现过拟合现象时，降低模型复杂度\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c70f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 下载，加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 下载数据集\n",
    "train_set = datasets.MNIST(\"../../dataset/mnist_data/\", train=True, download=True, transform=pipeline)\n",
    "test_set = datasets.MNIST(\"../../dataset/mnist_data/\", train=False, download=True, transform=pipeline)\n",
    "\n",
    "# 加载数据\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) # shuffle 打乱数据\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ae3fa",
   "metadata": {},
   "source": [
    "### 插入代码，显示MNIST中的图片\n",
    "#### 1. 读取文件\n",
    "#### 2. 提取图片\n",
    "#### 3. 转换图片\n",
    "#### 4. 显示图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11574dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 读取文件\n",
    "with open(\"../../dataset/mnist_data/MNIST/raw/train-images-idx3-ubyte\",\"rb\") as f: # python中读取文件\n",
    "    file = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8f44f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 24, 24, 24, 294, 310, 373, 38, 358, 597, 583, 295, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 54, 148, 340, 368, 595, 595, 595, 595, 595, 549, 370, 595, 578, 405, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 73, 568, 595, 595, 595, 595, 595, 595, 595, 595, 593, 147, 130, 130, 86, 57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 537, 595, 595, 595, 595, 595, 408, 386, 583, 577, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 342, 263, 595, 595, 517, 17, 0, 67, 340, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 1, 340, 595, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 313, 595, 400, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 400, 595, 112, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 577, 549, 352, 264, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 576, 595, 595, 281, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 390, 595, 595, 336, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 147, 594, 595, 391, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 585, 595, 585, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 70, 304, 387, 595, 595, 519, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 57, 328, 553, 595, 595, 595, 592, 386, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 276, 545, 595, 595, 595, 595, 513, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 102, 531, 595, 595, 595, 595, 408, 129, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 369, 537, 595, 595, 595, 595, 405, 128, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 370, 550, 595, 595, 595, 595, 580, 307, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 310, 595, 595, 595, 530, 309, 306, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 2. 提取图片\n",
    "image1 = [int(str(item).encode('ascii'),16) for item in file[16: 16+784]]\n",
    "print(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaacf374",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m image1_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(image1, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(image1_np\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image1' is not defined"
     ]
    }
   ],
   "source": [
    "# 3. 转换图片\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image1_np = np.array(image1, dtype=np.uint8).reshape(28,28,1)\n",
    "print(image1_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e48856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. 显示图片\n",
    "cv2.imwrite(\"digit.jpg\",image1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ee1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 构建网络模型（***）\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 卷积层定义\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5) # 1: 灰度图片的通道， 10: 输出通道， 5: kernel\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3) # 10: 输入通道， 20: 输出通道， 3: kernel\n",
    "        # 全连接层定义\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) # 20*10*10: 输入通道， 500: 输出通道\n",
    "        self.fc2 = nn.Linear(500, 10) # 500: 输入通道， 10: 输出通道\n",
    "        \n",
    "    \n",
    "    # 反向传播\n",
    "    def forward(self, x):\n",
    "        input_size = x.size(0) # batch_size\n",
    "        x = self.conv1(x) # 输入: batch*1*28*28 , 输出: batch*10*24*24 ( 28 - 5 + 1 = 24 )\n",
    "        x = F.relu(x) # 保持shape不变， 输出: batch*10*24*24\n",
    "        x = F.max_pool2d(x, 2, 2) # 输入: batch*10*24*24 输出: batch*10*12*12\n",
    "        \n",
    "        x = self.conv2(x) # 输入: batch*10*12*12 输出: batch*20*10*10 ( 12 - 3 + 1 = 10 )\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(input_size, -1) # 拉平, -1 自动计算维度， 20*10*10= 2000\n",
    "        \n",
    "        x = self.fc1(x) # 输入: batch*2000 输出: batch*500\n",
    "        x = F.relu(x) # 保持shape不变\n",
    "        \n",
    "        x = self.fc2(x) # 输入: batch*500 输出: batch * 10\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1) # 计算分类后，每个数字的概率值\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea6eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 定义优化器\n",
    "model = Net().to(DEVICE_MACBOOK)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b1c29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 定义训练方法\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    # 模型训练\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        # 部署到DEVICE上去\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 梯度初始化为0\n",
    "        optimizer.zero_grad()\n",
    "        # 训练后的结果\n",
    "        output = model(data)\n",
    "        # 计算损失（损失就是差距，和真实值的差距）\n",
    "        loss = F.cross_entropy(output, target) # (cross_entropy：适合交叉熵函数，如果是二分类问题，就用sigmod函数)\n",
    "        # 找到概率真最大的下标\n",
    "        #pred = output.max(1, keepdim=True) # 或者 pred = output.argmax(dim=1)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 3000 == 0:\n",
    "            print(\"Train Epoch : {} \\t Loss : {:.6f}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84d3cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 定义测试方法\n",
    "def test_model(model, device, test_loader):\n",
    "    # 模型验证\n",
    "    model.eval()\n",
    "    # 正确率\n",
    "    correct = 0.0\n",
    "    # 测试损失\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad(): # 不会计算梯度，也不会进行反向传播\n",
    "        for data, target in test_loader:\n",
    "            #部署到device上\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 测试数据\n",
    "            output = model(data)\n",
    "            # 计算测试损失\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            # 找到概率值最大的下标\n",
    "            pred = output.max(1, keepdim=True)[1] # 值， 索引\n",
    "            # pred = torch.max(output, dim=1)\n",
    "            # pred = output.argmax(dim=1)\n",
    "            # 累计正确的值\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            images = data.cpu().numpy()\n",
    "            labels = target.cpu().numpy()\n",
    "            pred = pred.cpu().numpy()\n",
    "            # batchsize * 1 * 28 * 28\n",
    "            for idx in range(images.shape[0]):\n",
    "                im_data = images[idx]\n",
    "                im_label = labels[idx]\n",
    "                im_pred = pred[idx]\n",
    "                im_data = im_data.transpose(1, 2, 0)\n",
    "                \n",
    "                print('label', im_label)\n",
    "                print('pred', im_pred)\n",
    "                cv2.imshow('imdata', im_data)\n",
    "                cv2.waitKey(0)\n",
    "        \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"Test -- Average loss : {:.4f}, Accuracy : {:.3f}\\n\".format(test_loss, 100.0 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5981dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch : 1 \t Loss : 0.030335\n",
      "label 9\n",
      "pred [9]\n",
      "label 8\n",
      "pred [8]\n",
      "label 2\n",
      "pred [2]\n",
      "label 7\n",
      "pred [7]\n",
      "label 0\n",
      "pred [0]\n",
      "label 8\n",
      "pred [8]\n",
      "label 9\n",
      "pred [9]\n",
      "label 3\n",
      "pred [3]\n",
      "label 6\n",
      "pred [6]\n",
      "label 1\n",
      "pred [1]\n",
      "label 2\n",
      "pred [2]\n",
      "label 5\n",
      "pred [5]\n",
      "label 0\n",
      "pred [0]\n",
      "label 4\n",
      "pred [4]\n",
      "label 6\n",
      "pred [6]\n",
      "label 4\n",
      "pred [4]\n",
      "label 7\n",
      "pred [7]\n",
      "label 6\n",
      "pred [6]\n",
      "label 9\n",
      "pred [9]\n",
      "label 7\n",
      "pred [7]\n",
      "label 1\n",
      "pred [1]\n",
      "label 7\n",
      "pred [7]\n",
      "label 7\n",
      "pred [7]\n",
      "label 2\n",
      "pred [2]\n",
      "label 5\n",
      "pred [5]\n",
      "label 7\n",
      "pred [7]\n",
      "label 4\n",
      "pred [4]\n",
      "label 3\n",
      "pred [3]\n",
      "label 4\n",
      "pred [4]\n",
      "label 6\n",
      "pred [6]\n",
      "label 9\n",
      "pred [2]\n",
      "label 9\n",
      "pred [9]\n",
      "label 3\n",
      "pred [3]\n",
      "label 3\n",
      "pred [3]\n",
      "label 0\n",
      "pred [0]\n",
      "label 0\n",
      "pred [0]\n",
      "label 7\n",
      "pred [7]\n",
      "label 1\n",
      "pred [1]\n",
      "label 6\n",
      "pred [6]\n",
      "label 5\n",
      "pred [5]\n",
      "label 7\n",
      "pred [7]\n",
      "label 3\n",
      "pred [3]\n",
      "label 1\n",
      "pred [1]\n",
      "label 0\n",
      "pred [0]\n",
      "label 1\n",
      "pred [1]\n",
      "label 6\n",
      "pred [6]\n",
      "label 2\n",
      "pred [2]\n",
      "label 6\n",
      "pred [6]\n",
      "label 3\n",
      "pred [3]\n",
      "label 8\n",
      "pred [8]\n",
      "label 8\n",
      "pred [8]\n",
      "label 7\n",
      "pred [7]\n",
      "label 6\n",
      "pred [6]\n",
      "label 4\n",
      "pred [4]\n",
      "label 1\n",
      "pred [1]\n",
      "label 8\n",
      "pred [8]\n",
      "label 3\n",
      "pred [3]\n",
      "label 1\n",
      "pred [1]\n"
     ]
    }
   ],
   "source": [
    "# 9 调用 方法7 / 8\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_model(model, DEVICE_MACBOOK, train_loader, optimizer, epoch)\n",
    "    test_model(model, DEVICE_MACBOOK, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816162fe-ae6c-4f31-a32a-a3973574c92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
